{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bba3cbaf-f480-490c-a284-e16da2cc1896",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 1) FACT_ORDERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e318434e-67a6-4e1a-b6cf-ce719aa55a64",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Databricks data profile. Run in Databricks to view."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1.subcommand+json": {
       "baseErrorDetails": null,
       "bindings": {},
       "collapsed": false,
       "command": "%python\nif hasattr(dbutils, \"data\") and hasattr(dbutils.data, \"summarize\"):\n  # setup\n  __data_summary_display_orig = display\n  __data_summary_dfs = []\n  def __data_summary_display_new(df):\n    # add only when result is going to be table type\n    __data_summary_df_modules = [\"pandas.core.frame\", \"databricks.koalas.frame\", \"pyspark.sql.dataframe\", \"pyspark.pandas.frame\", \"pyspark.sql.connect.dataframe\", \"pyspark.sql.classic.dataframe\"]\n    if (type(df).__module__ in __data_summary_df_modules and type(df).__name__ == 'DataFrame') or isinstance(df, list):\n      __data_summary_dfs.append(df)\n  display = __data_summary_display_new\n\n  def __data_summary_user_code_fn():\n    import base64\n    exec(base64.standard_b64decode(\"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\").decode())\n\n  try:\n    # run user code\n    __data_summary_user_code_fn()\n\n    # run on valid tableResultIndex\n    if len(__data_summary_dfs) > 0:\n      # run summarize\n      if type(__data_summary_dfs[0]).__module__ == \"databricks.koalas.frame\":\n        # koalas dataframe\n        dbutils.data.summarize(__data_summary_dfs[0].to_spark())\n      elif type(__data_summary_dfs[0]).__module__ == \"pandas.core.frame\":\n        # pandas dataframe\n        dbutils.data.summarize(spark.createDataFrame(__data_summary_dfs[0]))\n      else:\n        dbutils.data.summarize(__data_summary_dfs[0])\n    else:\n        displayHTML(\"dataframe no longer exists. If you're using dataframe.display(), use display(dataframe) instead.\")\n\n  finally:\n    display = __data_summary_display_orig\n    del __data_summary_display_new\n    del __data_summary_display_orig\n    del __data_summary_dfs\n    del __data_summary_user_code_fn\nelse:\n  print(\"This DBR version does not support data profiles.\")",
       "commandTitle": "Profil de données 1",
       "commandType": "auto",
       "commandVersion": 0,
       "commentThread": [],
       "commentsVisible": false,
       "contentSha256Hex": null,
       "customPlotOptions": {},
       "datasetPreviewNameToCmdIdMap": {},
       "diffDeletes": [],
       "diffInserts": [],
       "displayType": "table",
       "error": null,
       "errorDetails": null,
       "errorSummary": null,
       "errorTraceType": null,
       "finishTime": 1767182586735,
       "globalVars": {},
       "guid": "",
       "height": "auto",
       "hideCommandCode": false,
       "hideCommandResult": false,
       "iPythonMetadata": null,
       "inputWidgets": {},
       "isLockedInExamMode": false,
       "latestAssumeRoleInfo": null,
       "latestUser": "a user",
       "latestUserId": null,
       "listResultMetadata": [
        [
         "mimeBundle",
         null
        ]
       ],
       "metadata": {
        "byteLimit": 2048000,
        "rowLimit": 10000
       },
       "nuid": "ebc29385-44b3-4531-83d6-a69004da4c98",
       "origId": 0,
       "parentHierarchy": [],
       "pivotAggregation": null,
       "pivotColumns": null,
       "position": 2.0,
       "resultDbfsErrorMessage": null,
       "resultDbfsStatus": "INLINED_IN_TREE",
       "results": null,
       "showCommandTitle": false,
       "startTime": 1767182572408,
       "state": "input",
       "streamStates": {},
       "subcommandOptions": null,
       "submitTime": 1767182572330,
       "subtype": "tableResultSubCmd.dataSummary",
       "tableResultIndex": 0,
       "tableResultSettingsMap": {},
       "useConsistentColors": false,
       "version": "CommandV1",
       "width": "auto",
       "workflows": null,
       "xColumns": null,
       "yColumns": null
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import sum,avg,col\n",
    "\n",
    "client_id     = dbutils.secrets.get(scope=\"kv-olist\", key=\"secret-client-id\")\n",
    "tenant_id     = dbutils.secrets.get(scope=\"kv-olist\", key=\"secret-tenant-id\")\n",
    "client_secret = dbutils.secrets.get(scope=\"kv-olist\", key=\"secret-client-mdp\")\n",
    "\n",
    "storage_account = \"oliststorageaccountbth74\"\n",
    "container_name = \"data\"\n",
    "\n",
    "spark.conf.set(f\"fs.azure.account.auth.type.{storage_account}.dfs.core.windows.net\", \"OAuth\")\n",
    "spark.conf.set(f\"fs.azure.account.oauth.provider.type.{storage_account}.dfs.core.windows.net\", \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\")\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.id.{storage_account}.dfs.core.windows.net\", client_id)\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.secret.{storage_account}.dfs.core.windows.net\", client_secret)\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.endpoint.{storage_account}.dfs.core.windows.net\", f\"https://login.microsoftonline.com/{tenant_id}/oauth2/token\")\n",
    "\n",
    "df_orders=spark.read.format(\"delta\").load(f\"abfss://{container_name}@{storage_account}.dfs.core.windows.net/silver/olist_orders_dataset\")\n",
    "\n",
    "df_payments=spark.read.format(\"delta\").load(f\"abfss://{container_name}@{storage_account}.dfs.core.windows.net/silver/olist_order_payments_dataset\")\n",
    "\n",
    "df_reviews=spark.read.format(\"delta\").load(f\"abfss://{container_name}@{storage_account}.dfs.core.windows.net/silver/olist_order_reviews_dataset\")\n",
    "\n",
    "df_pivot_payments=df_payments.groupBy(\"order_id\").pivot(\"payment_type\").agg(sum(\"payment_value\")).fillna(0)\n",
    "\n",
    "df_reviews_filtered=df_reviews.groupBy(\"order_id\").agg(avg(\"review_score\").alias(\"avg_review_score\"))\n",
    "\n",
    "df_orders_joined=df_orders.join(df_pivot_payments, on=\"order_id\", how=\"left\").join(df_reviews_filtered,on=\"order_id\",how=\"left\")\n",
    "\n",
    "df_orders_joined=df_orders_joined.withColumn(\"total_order\",col(\"boleto\")+col(\"credit_card\")+col(\"debit_card\")+col(\"voucher\"))\n",
    "\n",
    "\n",
    "df_orders_joined.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\",\"true\").save(f\"abfss://{container_name}@{storage_account}.dfs.core.windows.net/gold/olist_fact_orders\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4033aadc-bb1a-41af-a631-20212b75aa2c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 2) FACT_ORDER_ITEMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "25e1b179-bc32-4470-b889-d55ffaf16475",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Databricks data profile. Run in Databricks to view."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1.subcommand+json": {
       "baseErrorDetails": null,
       "bindings": {},
       "collapsed": false,
       "command": "%python\nif hasattr(dbutils, \"data\") and hasattr(dbutils.data, \"summarize\"):\n  # setup\n  __data_summary_display_orig = display\n  __data_summary_dfs = []\n  def __data_summary_display_new(df):\n    # add only when result is going to be table type\n    __data_summary_df_modules = [\"pandas.core.frame\", \"databricks.koalas.frame\", \"pyspark.sql.dataframe\", \"pyspark.pandas.frame\", \"pyspark.sql.connect.dataframe\", \"pyspark.sql.classic.dataframe\"]\n    if (type(df).__module__ in __data_summary_df_modules and type(df).__name__ == 'DataFrame') or isinstance(df, list):\n      __data_summary_dfs.append(df)\n  display = __data_summary_display_new\n\n  def __data_summary_user_code_fn():\n    import base64\n    exec(base64.standard_b64decode(\"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\").decode())\n\n  try:\n    # run user code\n    __data_summary_user_code_fn()\n\n    # run on valid tableResultIndex\n    if len(__data_summary_dfs) > 0:\n      # run summarize\n      if type(__data_summary_dfs[0]).__module__ == \"databricks.koalas.frame\":\n        # koalas dataframe\n        dbutils.data.summarize(__data_summary_dfs[0].to_spark())\n      elif type(__data_summary_dfs[0]).__module__ == \"pandas.core.frame\":\n        # pandas dataframe\n        dbutils.data.summarize(spark.createDataFrame(__data_summary_dfs[0]))\n      else:\n        dbutils.data.summarize(__data_summary_dfs[0])\n    else:\n        displayHTML(\"dataframe no longer exists. If you're using dataframe.display(), use display(dataframe) instead.\")\n\n  finally:\n    display = __data_summary_display_orig\n    del __data_summary_display_new\n    del __data_summary_display_orig\n    del __data_summary_dfs\n    del __data_summary_user_code_fn\nelse:\n  print(\"This DBR version does not support data profiles.\")",
       "commandTitle": "Profil de données 1",
       "commandType": "auto",
       "commandVersion": 0,
       "commentThread": [],
       "commentsVisible": false,
       "contentSha256Hex": null,
       "customPlotOptions": {},
       "datasetPreviewNameToCmdIdMap": {},
       "diffDeletes": [],
       "diffInserts": [],
       "displayType": "table",
       "error": null,
       "errorDetails": null,
       "errorSummary": null,
       "errorTraceType": null,
       "finishTime": 1767111497297,
       "globalVars": {},
       "guid": "",
       "height": "auto",
       "hideCommandCode": false,
       "hideCommandResult": false,
       "iPythonMetadata": null,
       "inputWidgets": {},
       "isLockedInExamMode": false,
       "latestAssumeRoleInfo": null,
       "latestUser": "a user",
       "latestUserId": null,
       "listResultMetadata": [
        [
         "mimeBundle",
         null
        ]
       ],
       "metadata": {
        "byteLimit": 2048000,
        "rowLimit": 10000
       },
       "nuid": "8e6e1ff7-172d-42cf-bc36-74741863eae1",
       "origId": 0,
       "parentHierarchy": [],
       "pivotAggregation": null,
       "pivotColumns": null,
       "position": 4.0,
       "resultDbfsErrorMessage": null,
       "resultDbfsStatus": "INLINED_IN_TREE",
       "results": null,
       "showCommandTitle": false,
       "startTime": 1767111493584,
       "state": "input",
       "streamStates": {},
       "subcommandOptions": null,
       "submitTime": 1767111493543,
       "subtype": "tableResultSubCmd.dataSummary",
       "tableResultIndex": 0,
       "tableResultSettingsMap": {},
       "useConsistentColors": false,
       "version": "CommandV1",
       "width": "auto",
       "workflows": null,
       "xColumns": null,
       "yColumns": null
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "client_id     = dbutils.secrets.get(scope=\"kv-olist\", key=\"secret-client-id\")\n",
    "tenant_id     = dbutils.secrets.get(scope=\"kv-olist\", key=\"secret-tenant-id\")\n",
    "client_secret = dbutils.secrets.get(scope=\"kv-olist\", key=\"secret-client-mdp\")\n",
    "\n",
    "storage_account = \"oliststorageaccountbth74\"\n",
    "container_name = \"data\"\n",
    "\n",
    "spark.conf.set(f\"fs.azure.account.auth.type.{storage_account}.dfs.core.windows.net\", \"OAuth\")\n",
    "spark.conf.set(f\"fs.azure.account.oauth.provider.type.{storage_account}.dfs.core.windows.net\", \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\")\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.id.{storage_account}.dfs.core.windows.net\", client_id)\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.secret.{storage_account}.dfs.core.windows.net\", client_secret)\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.endpoint.{storage_account}.dfs.core.windows.net\", f\"https://login.microsoftonline.com/{tenant_id}/oauth2/token\")\n",
    "\n",
    "df_order_items=spark.read.format(\"delta\").load(f\"abfss://{container_name}@{storage_account}.dfs.core.windows.net/silver/olist_order_items_dataset\")\n",
    "\n",
    "df_orders=spark.read.format(\"delta\").load(f\"abfss://{container_name}@{storage_account}.dfs.core.windows.net/silver/olist_orders_dataset\")\n",
    "\n",
    "df_customerId=df_orders.select(\"order_id\",\"customer_id\",\"order_purchase_timestamp\")\n",
    "\n",
    "df_order_items_joined=df_order_items.join(df_customerId,on=\"order_id\",how=\"inner\")\n",
    "\n",
    "df_order_items_joined=df_order_items_joined.withColumn(\"total_order\",col(\"price\")+col(\"freight_value\"))\n",
    "\n",
    "df_order_items_joined.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\").save(f\"abfss://{container_name}@{storage_account}.dfs.core.windows.net/gold/olist_fact_order_items\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "524d03d9-9839-4e59-bd35-f2f810067f24",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 3) DIM_PRODUCTS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f345a95f-1f46-477a-a705-eae382c3d3c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Databricks data profile. Run in Databricks to view."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1.subcommand+json": {
       "baseErrorDetails": null,
       "bindings": {},
       "collapsed": false,
       "command": "%python\nif hasattr(dbutils, \"data\") and hasattr(dbutils.data, \"summarize\"):\n  # setup\n  __data_summary_display_orig = display\n  __data_summary_dfs = []\n  def __data_summary_display_new(df):\n    # add only when result is going to be table type\n    __data_summary_df_modules = [\"pandas.core.frame\", \"databricks.koalas.frame\", \"pyspark.sql.dataframe\", \"pyspark.pandas.frame\", \"pyspark.sql.connect.dataframe\", \"pyspark.sql.classic.dataframe\"]\n    if (type(df).__module__ in __data_summary_df_modules and type(df).__name__ == 'DataFrame') or isinstance(df, list):\n      __data_summary_dfs.append(df)\n  display = __data_summary_display_new\n\n  def __data_summary_user_code_fn():\n    import base64\n    exec(base64.standard_b64decode(\"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\").decode())\n\n  try:\n    # run user code\n    __data_summary_user_code_fn()\n\n    # run on valid tableResultIndex\n    if len(__data_summary_dfs) > 0:\n      # run summarize\n      if type(__data_summary_dfs[0]).__module__ == \"databricks.koalas.frame\":\n        # koalas dataframe\n        dbutils.data.summarize(__data_summary_dfs[0].to_spark())\n      elif type(__data_summary_dfs[0]).__module__ == \"pandas.core.frame\":\n        # pandas dataframe\n        dbutils.data.summarize(spark.createDataFrame(__data_summary_dfs[0]))\n      else:\n        dbutils.data.summarize(__data_summary_dfs[0])\n    else:\n        displayHTML(\"dataframe no longer exists. If you're using dataframe.display(), use display(dataframe) instead.\")\n\n  finally:\n    display = __data_summary_display_orig\n    del __data_summary_display_new\n    del __data_summary_display_orig\n    del __data_summary_dfs\n    del __data_summary_user_code_fn\nelse:\n  print(\"This DBR version does not support data profiles.\")",
       "commandTitle": "Profil de données 1",
       "commandType": "auto",
       "commandVersion": 0,
       "commentThread": [],
       "commentsVisible": false,
       "contentSha256Hex": null,
       "customPlotOptions": {},
       "datasetPreviewNameToCmdIdMap": {},
       "diffDeletes": [],
       "diffInserts": [],
       "displayType": "table",
       "error": null,
       "errorDetails": null,
       "errorSummary": null,
       "errorTraceType": null,
       "finishTime": 1766931283404,
       "globalVars": {},
       "guid": "",
       "height": "auto",
       "hideCommandCode": false,
       "hideCommandResult": false,
       "iPythonMetadata": null,
       "inputWidgets": {},
       "isLockedInExamMode": false,
       "latestAssumeRoleInfo": null,
       "latestUser": "a user",
       "latestUserId": null,
       "listResultMetadata": [
        [
         "mimeBundle",
         null
        ]
       ],
       "metadata": {
        "byteLimit": 2048000,
        "rowLimit": 10000
       },
       "nuid": "ad817638-d7a7-4afa-a349-c8bec5b860c2",
       "origId": 0,
       "parentHierarchy": [],
       "pivotAggregation": null,
       "pivotColumns": null,
       "position": 5.0,
       "resultDbfsErrorMessage": null,
       "resultDbfsStatus": "INLINED_IN_TREE",
       "results": null,
       "showCommandTitle": false,
       "startTime": 1766931280006,
       "state": "input",
       "streamStates": {},
       "subcommandOptions": null,
       "submitTime": 1766931279973,
       "subtype": "tableResultSubCmd.dataSummary",
       "tableResultIndex": 0,
       "tableResultSettingsMap": {},
       "useConsistentColors": false,
       "version": "CommandV1",
       "width": "auto",
       "workflows": null,
       "xColumns": null,
       "yColumns": null
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import coalesce,col,lit\n",
    "\n",
    "client_id     = dbutils.secrets.get(scope=\"kv-olist\", key=\"secret-client-id\")\n",
    "tenant_id     = dbutils.secrets.get(scope=\"kv-olist\", key=\"secret-tenant-id\")\n",
    "client_secret = dbutils.secrets.get(scope=\"kv-olist\", key=\"secret-client-mdp\")\n",
    "\n",
    "storage_account = \"oliststorageaccountbth74\"\n",
    "container_name = \"data\"\n",
    "\n",
    "spark.conf.set(f\"fs.azure.account.auth.type.{storage_account}.dfs.core.windows.net\", \"OAuth\")\n",
    "spark.conf.set(f\"fs.azure.account.oauth.provider.type.{storage_account}.dfs.core.windows.net\", \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\")\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.id.{storage_account}.dfs.core.windows.net\", client_id)\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.secret.{storage_account}.dfs.core.windows.net\", client_secret)\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.endpoint.{storage_account}.dfs.core.windows.net\", f\"https://login.microsoftonline.com/{tenant_id}/oauth2/token\")\n",
    "\n",
    "\n",
    "df_products=spark.read.format(\"delta\").load(f\"abfss://{container_name}@{storage_account}.dfs.core.windows.net/silver/olist_products_dataset\")\n",
    "\n",
    "df_translations=spark.read.format(\"delta\").load(f\"abfss://{container_name}@{storage_account}.dfs.core.windows.net/silver/product_category_name_translation\")\n",
    "\n",
    "df_products_translated=df_products.join(df_translations,on=\"product_category_name\",how=\"left\")\n",
    "\n",
    "df_products_translated=df_products_translated.withColumn(\n",
    "    \"product_category_name_english\",\n",
    "    coalesce(col(\"product_category_name_english\"),col(\"product_category_name\"),lit(\"unknown\")))\n",
    "\n",
    "df_products_translated=df_products_translated.drop(\"product_category_name\")\n",
    "\n",
    "df_products_translated=df_products_translated.withColumnRenamed(\"product_category_name_english\",\"product_category_name\")\n",
    "\n",
    "df_products_translated.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\").save(f\"abfss://{container_name}@{storage_account}.dfs.core.windows.net/gold/olist_dim_products\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "38090992-c1f4-4047-aecb-3fe7f892ff6a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 4) DIM_CUSTOMERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f50a909c-b285-49f7-aea0-1331368b6ddc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Databricks data profile. Run in Databricks to view."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1.subcommand+json": {
       "baseErrorDetails": null,
       "bindings": {},
       "collapsed": false,
       "command": "%python\nif hasattr(dbutils, \"data\") and hasattr(dbutils.data, \"summarize\"):\n  # setup\n  __data_summary_display_orig = display\n  __data_summary_dfs = []\n  def __data_summary_display_new(df):\n    # add only when result is going to be table type\n    __data_summary_df_modules = [\"pandas.core.frame\", \"databricks.koalas.frame\", \"pyspark.sql.dataframe\", \"pyspark.pandas.frame\", \"pyspark.sql.connect.dataframe\", \"pyspark.sql.classic.dataframe\"]\n    if (type(df).__module__ in __data_summary_df_modules and type(df).__name__ == 'DataFrame') or isinstance(df, list):\n      __data_summary_dfs.append(df)\n  display = __data_summary_display_new\n\n  def __data_summary_user_code_fn():\n    import base64\n    exec(base64.standard_b64decode(\"ZnJvbSBweXNwYXJrLnNxbC5mdW5jdGlvbnMgaW1wb3J0IGNvYWxlc2NlLGNvbCxsaXQKCmNsaWVudF9pZCAgICAgPSBkYnV0aWxzLnNlY3JldHMuZ2V0KHNjb3BlPSJrdi1vbGlzdCIsIGtleT0ic2VjcmV0LWNsaWVudC1pZCIpCnRlbmFudF9pZCAgICAgPSBkYnV0aWxzLnNlY3JldHMuZ2V0KHNjb3BlPSJrdi1vbGlzdCIsIGtleT0ic2VjcmV0LXRlbmFudC1pZCIpCmNsaWVudF9zZWNyZXQgPSBkYnV0aWxzLnNlY3JldHMuZ2V0KHNjb3BlPSJrdi1vbGlzdCIsIGtleT0ic2VjcmV0LWNsaWVudC1tZHAiKQoKc3RvcmFnZV9hY2NvdW50ID0gIm9saXN0c3RvcmFnZWFjY291bnRidGg3NCIKY29udGFpbmVyX25hbWUgPSAiZGF0YSIKCnNwYXJrLmNvbmYuc2V0KGYiZnMuYXp1cmUuYWNjb3VudC5hdXRoLnR5cGUue3N0b3JhZ2VfYWNjb3VudH0uZGZzLmNvcmUud2luZG93cy5uZXQiLCAiT0F1dGgiKQpzcGFyay5jb25mLnNldChmImZzLmF6dXJlLmFjY291bnQub2F1dGgucHJvdmlkZXIudHlwZS57c3RvcmFnZV9hY2NvdW50fS5kZnMuY29yZS53aW5kb3dzLm5ldCIsICJvcmcuYXBhY2hlLmhhZG9vcC5mcy5henVyZWJmcy5vYXV0aDIuQ2xpZW50Q3JlZHNUb2tlblByb3ZpZGVyIikKc3BhcmsuY29uZi5zZXQoZiJmcy5henVyZS5hY2NvdW50Lm9hdXRoMi5jbGllbnQuaWQue3N0b3JhZ2VfYWNjb3VudH0uZGZzLmNvcmUud2luZG93cy5uZXQiLCBjbGllbnRfaWQpCnNwYXJrLmNvbmYuc2V0KGYiZnMuYXp1cmUuYWNjb3VudC5vYXV0aDIuY2xpZW50LnNlY3JldC57c3RvcmFnZV9hY2NvdW50fS5kZnMuY29yZS53aW5kb3dzLm5ldCIsIGNsaWVudF9zZWNyZXQpCnNwYXJrLmNvbmYuc2V0KGYiZnMuYXp1cmUuYWNjb3VudC5vYXV0aDIuY2xpZW50LmVuZHBvaW50LntzdG9yYWdlX2FjY291bnR9LmRmcy5jb3JlLndpbmRvd3MubmV0IiwgZiJodHRwczovL2xvZ2luLm1pY3Jvc29mdG9ubGluZS5jb20ve3RlbmFudF9pZH0vb2F1dGgyL3Rva2VuIikKCmRmX2N1c3RvbWVycz1zcGFyay5yZWFkLmZvcm1hdCgiZGVsdGEiKS5sb2FkKGYiYWJmc3M6Ly97Y29udGFpbmVyX25hbWV9QHtzdG9yYWdlX2FjY291bnR9LmRmcy5jb3JlLndpbmRvd3MubmV0L3NpbHZlci9vbGlzdF9jdXN0b21lcnNfZGF0YXNldCIpCgpkZl9nZW89c3BhcmsucmVhZC5mb3JtYXQoImRlbHRhIikubG9hZChmImFiZnNzOi8ve2NvbnRhaW5lcl9uYW1lfUB7c3RvcmFnZV9hY2NvdW50fS5kZnMuY29yZS53aW5kb3dzLm5ldC9zaWx2ZXIvb2xpc3RfZ2VvbG9jYXRpb25fZGF0YXNldCIpCgpkaXNwbGF5KGRmX2N1c3RvbWVycykKZGlzcGxheShkZl9nZW8pCg==\").decode())\n\n  try:\n    # run user code\n    __data_summary_user_code_fn()\n\n    # run on valid tableResultIndex\n    if len(__data_summary_dfs) > 1:\n      # run summarize\n      if type(__data_summary_dfs[1]).__module__ == \"databricks.koalas.frame\":\n        # koalas dataframe\n        dbutils.data.summarize(__data_summary_dfs[1].to_spark())\n      elif type(__data_summary_dfs[1]).__module__ == \"pandas.core.frame\":\n        # pandas dataframe\n        dbutils.data.summarize(spark.createDataFrame(__data_summary_dfs[1]))\n      else:\n        dbutils.data.summarize(__data_summary_dfs[1])\n    else:\n        displayHTML(\"dataframe no longer exists. If you're using dataframe.display(), use display(dataframe) instead.\")\n\n  finally:\n    display = __data_summary_display_orig\n    del __data_summary_display_new\n    del __data_summary_display_orig\n    del __data_summary_dfs\n    del __data_summary_user_code_fn\nelse:\n  print(\"This DBR version does not support data profiles.\")",
       "commandTitle": "Profil de données 1",
       "commandType": "auto",
       "commandVersion": 0,
       "commentThread": [],
       "commentsVisible": false,
       "contentSha256Hex": null,
       "customPlotOptions": {},
       "datasetPreviewNameToCmdIdMap": {},
       "diffDeletes": [],
       "diffInserts": [],
       "displayType": "table",
       "error": null,
       "errorDetails": null,
       "errorSummary": null,
       "errorTraceType": null,
       "finishTime": 1766932402586,
       "globalVars": {},
       "guid": "",
       "height": "auto",
       "hideCommandCode": false,
       "hideCommandResult": false,
       "iPythonMetadata": null,
       "inputWidgets": {},
       "isLockedInExamMode": false,
       "latestAssumeRoleInfo": null,
       "latestUser": "a user",
       "latestUserId": null,
       "listResultMetadata": [
        [
         "mimeBundle",
         null
        ]
       ],
       "metadata": {
        "byteLimit": 2048000,
        "rowLimit": 10000
       },
       "nuid": "58048cf4-d2fa-452d-bcc5-ee46f207d22d",
       "origId": 0,
       "parentHierarchy": [],
       "pivotAggregation": null,
       "pivotColumns": null,
       "position": 6.5,
       "resultDbfsErrorMessage": null,
       "resultDbfsStatus": "INLINED_IN_TREE",
       "results": null,
       "showCommandTitle": false,
       "startTime": 1766932398380,
       "state": "input",
       "streamStates": {},
       "subcommandOptions": null,
       "submitTime": 1766932398303,
       "subtype": "tableResultSubCmd.dataSummary",
       "tableResultIndex": 1,
       "tableResultSettingsMap": {},
       "useConsistentColors": false,
       "version": "CommandV1",
       "width": "auto",
       "workflows": null,
       "xColumns": null,
       "yColumns": null
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Databricks data profile. Run in Databricks to view."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1.subcommand+json": {
       "baseErrorDetails": null,
       "bindings": {},
       "collapsed": false,
       "command": "%python\nif hasattr(dbutils, \"data\") and hasattr(dbutils.data, \"summarize\"):\n  # setup\n  __data_summary_display_orig = display\n  __data_summary_dfs = []\n  def __data_summary_display_new(df):\n    # add only when result is going to be table type\n    __data_summary_df_modules = [\"pandas.core.frame\", \"databricks.koalas.frame\", \"pyspark.sql.dataframe\", \"pyspark.pandas.frame\", \"pyspark.sql.connect.dataframe\", \"pyspark.sql.classic.dataframe\"]\n    if (type(df).__module__ in __data_summary_df_modules and type(df).__name__ == 'DataFrame') or isinstance(df, list):\n      __data_summary_dfs.append(df)\n  display = __data_summary_display_new\n\n  def __data_summary_user_code_fn():\n    import base64\n    exec(base64.standard_b64decode(\"ZnJvbSBweXNwYXJrLnNxbC5mdW5jdGlvbnMgaW1wb3J0IGNvYWxlc2NlLGNvbCxsaXQKCmNsaWVudF9pZCAgICAgPSBkYnV0aWxzLnNlY3JldHMuZ2V0KHNjb3BlPSJrdi1vbGlzdCIsIGtleT0ic2VjcmV0LWNsaWVudC1pZCIpCnRlbmFudF9pZCAgICAgPSBkYnV0aWxzLnNlY3JldHMuZ2V0KHNjb3BlPSJrdi1vbGlzdCIsIGtleT0ic2VjcmV0LXRlbmFudC1pZCIpCmNsaWVudF9zZWNyZXQgPSBkYnV0aWxzLnNlY3JldHMuZ2V0KHNjb3BlPSJrdi1vbGlzdCIsIGtleT0ic2VjcmV0LWNsaWVudC1tZHAiKQoKc3RvcmFnZV9hY2NvdW50ID0gIm9saXN0c3RvcmFnZWFjY291bnRidGg3NCIKY29udGFpbmVyX25hbWUgPSAiZGF0YSIKCnNwYXJrLmNvbmYuc2V0KGYiZnMuYXp1cmUuYWNjb3VudC5hdXRoLnR5cGUue3N0b3JhZ2VfYWNjb3VudH0uZGZzLmNvcmUud2luZG93cy5uZXQiLCAiT0F1dGgiKQpzcGFyay5jb25mLnNldChmImZzLmF6dXJlLmFjY291bnQub2F1dGgucHJvdmlkZXIudHlwZS57c3RvcmFnZV9hY2NvdW50fS5kZnMuY29yZS53aW5kb3dzLm5ldCIsICJvcmcuYXBhY2hlLmhhZG9vcC5mcy5henVyZWJmcy5vYXV0aDIuQ2xpZW50Q3JlZHNUb2tlblByb3ZpZGVyIikKc3BhcmsuY29uZi5zZXQoZiJmcy5henVyZS5hY2NvdW50Lm9hdXRoMi5jbGllbnQuaWQue3N0b3JhZ2VfYWNjb3VudH0uZGZzLmNvcmUud2luZG93cy5uZXQiLCBjbGllbnRfaWQpCnNwYXJrLmNvbmYuc2V0KGYiZnMuYXp1cmUuYWNjb3VudC5vYXV0aDIuY2xpZW50LnNlY3JldC57c3RvcmFnZV9hY2NvdW50fS5kZnMuY29yZS53aW5kb3dzLm5ldCIsIGNsaWVudF9zZWNyZXQpCnNwYXJrLmNvbmYuc2V0KGYiZnMuYXp1cmUuYWNjb3VudC5vYXV0aDIuY2xpZW50LmVuZHBvaW50LntzdG9yYWdlX2FjY291bnR9LmRmcy5jb3JlLndpbmRvd3MubmV0IiwgZiJodHRwczovL2xvZ2luLm1pY3Jvc29mdG9ubGluZS5jb20ve3RlbmFudF9pZH0vb2F1dGgyL3Rva2VuIikKCmRmX2N1c3RvbWVycz1zcGFyay5yZWFkLmZvcm1hdCgiZGVsdGEiKS5sb2FkKGYiYWJmc3M6Ly97Y29udGFpbmVyX25hbWV9QHtzdG9yYWdlX2FjY291bnR9LmRmcy5jb3JlLndpbmRvd3MubmV0L3NpbHZlci9vbGlzdF9jdXN0b21lcnNfZGF0YXNldCIpCgpkZl9nZW89c3BhcmsucmVhZC5mb3JtYXQoImRlbHRhIikubG9hZChmImFiZnNzOi8ve2NvbnRhaW5lcl9uYW1lfUB7c3RvcmFnZV9hY2NvdW50fS5kZnMuY29yZS53aW5kb3dzLm5ldC9zaWx2ZXIvb2xpc3RfZ2VvbG9jYXRpb25fZGF0YXNldCIpCgpkaXNwbGF5KGRmX2N1c3RvbWVycykKZGlzcGxheShkZl9nZW8pCg==\").decode())\n\n  try:\n    # run user code\n    __data_summary_user_code_fn()\n\n    # run on valid tableResultIndex\n    if len(__data_summary_dfs) > 0:\n      # run summarize\n      if type(__data_summary_dfs[0]).__module__ == \"databricks.koalas.frame\":\n        # koalas dataframe\n        dbutils.data.summarize(__data_summary_dfs[0].to_spark())\n      elif type(__data_summary_dfs[0]).__module__ == \"pandas.core.frame\":\n        # pandas dataframe\n        dbutils.data.summarize(spark.createDataFrame(__data_summary_dfs[0]))\n      else:\n        dbutils.data.summarize(__data_summary_dfs[0])\n    else:\n        displayHTML(\"dataframe no longer exists. If you're using dataframe.display(), use display(dataframe) instead.\")\n\n  finally:\n    display = __data_summary_display_orig\n    del __data_summary_display_new\n    del __data_summary_display_orig\n    del __data_summary_dfs\n    del __data_summary_user_code_fn\nelse:\n  print(\"This DBR version does not support data profiles.\")",
       "commandTitle": "Profil de données 1",
       "commandType": "auto",
       "commandVersion": 0,
       "commentThread": [],
       "commentsVisible": false,
       "contentSha256Hex": null,
       "customPlotOptions": {},
       "datasetPreviewNameToCmdIdMap": {},
       "diffDeletes": [],
       "diffInserts": [],
       "displayType": "table",
       "error": null,
       "errorDetails": null,
       "errorSummary": null,
       "errorTraceType": null,
       "finishTime": 1766932405394,
       "globalVars": {},
       "guid": "",
       "height": "auto",
       "hideCommandCode": false,
       "hideCommandResult": false,
       "iPythonMetadata": null,
       "inputWidgets": {},
       "isLockedInExamMode": false,
       "latestAssumeRoleInfo": null,
       "latestUser": "a user",
       "latestUserId": null,
       "listResultMetadata": [
        [
         "mimeBundle",
         null
        ]
       ],
       "metadata": {
        "byteLimit": 2048000,
        "rowLimit": 10000
       },
       "nuid": "7da72acf-6ce1-4b33-b932-2b0a0f9dc0a5",
       "origId": 0,
       "parentHierarchy": [],
       "pivotAggregation": null,
       "pivotColumns": null,
       "position": 6.5,
       "resultDbfsErrorMessage": null,
       "resultDbfsStatus": "INLINED_IN_TREE",
       "results": null,
       "showCommandTitle": false,
       "startTime": 1766932402601,
       "state": "input",
       "streamStates": {},
       "subcommandOptions": null,
       "submitTime": 1766932400396,
       "subtype": "tableResultSubCmd.dataSummary",
       "tableResultIndex": 0,
       "tableResultSettingsMap": {},
       "useConsistentColors": false,
       "version": "CommandV1",
       "width": "auto",
       "workflows": null,
       "xColumns": null,
       "yColumns": null
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "client_id     = dbutils.secrets.get(scope=\"kv-olist\", key=\"secret-client-id\")\n",
    "tenant_id     = dbutils.secrets.get(scope=\"kv-olist\", key=\"secret-tenant-id\")\n",
    "client_secret = dbutils.secrets.get(scope=\"kv-olist\", key=\"secret-client-mdp\")\n",
    "\n",
    "storage_account = \"oliststorageaccountbth74\"\n",
    "container_name = \"data\"\n",
    "\n",
    "spark.conf.set(f\"fs.azure.account.auth.type.{storage_account}.dfs.core.windows.net\", \"OAuth\")\n",
    "spark.conf.set(f\"fs.azure.account.oauth.provider.type.{storage_account}.dfs.core.windows.net\", \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\")\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.id.{storage_account}.dfs.core.windows.net\", client_id)\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.secret.{storage_account}.dfs.core.windows.net\", client_secret)\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.endpoint.{storage_account}.dfs.core.windows.net\", f\"https://login.microsoftonline.com/{tenant_id}/oauth2/token\")\n",
    "\n",
    "df_customers=spark.read.format(\"delta\").load(f\"abfss://{container_name}@{storage_account}.dfs.core.windows.net/silver/olist_customers_dataset\")\n",
    "\n",
    "df_customers.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\").save(f\"abfss://{container_name}@{storage_account}.dfs.core.windows.net/gold/olist_dim_customers\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "67b8b183-bbe0-476a-ba80-a29e1bdced2b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 5) DIM_SELLERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2ea955f0-0ccd-4447-8d41-83134f001690",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Databricks data profile. Run in Databricks to view."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1.subcommand+json": {
       "baseErrorDetails": null,
       "bindings": {},
       "collapsed": false,
       "command": "%python\nif hasattr(dbutils, \"data\") and hasattr(dbutils.data, \"summarize\"):\n  # setup\n  __data_summary_display_orig = display\n  __data_summary_dfs = []\n  def __data_summary_display_new(df):\n    # add only when result is going to be table type\n    __data_summary_df_modules = [\"pandas.core.frame\", \"databricks.koalas.frame\", \"pyspark.sql.dataframe\", \"pyspark.pandas.frame\", \"pyspark.sql.connect.dataframe\", \"pyspark.sql.classic.dataframe\"]\n    if (type(df).__module__ in __data_summary_df_modules and type(df).__name__ == 'DataFrame') or isinstance(df, list):\n      __data_summary_dfs.append(df)\n  display = __data_summary_display_new\n\n  def __data_summary_user_code_fn():\n    import base64\n    exec(base64.standard_b64decode(\"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\").decode())\n\n  try:\n    # run user code\n    __data_summary_user_code_fn()\n\n    # run on valid tableResultIndex\n    if len(__data_summary_dfs) > 0:\n      # run summarize\n      if type(__data_summary_dfs[0]).__module__ == \"databricks.koalas.frame\":\n        # koalas dataframe\n        dbutils.data.summarize(__data_summary_dfs[0].to_spark())\n      elif type(__data_summary_dfs[0]).__module__ == \"pandas.core.frame\":\n        # pandas dataframe\n        dbutils.data.summarize(spark.createDataFrame(__data_summary_dfs[0]))\n      else:\n        dbutils.data.summarize(__data_summary_dfs[0])\n    else:\n        displayHTML(\"dataframe no longer exists. If you're using dataframe.display(), use display(dataframe) instead.\")\n\n  finally:\n    display = __data_summary_display_orig\n    del __data_summary_display_new\n    del __data_summary_display_orig\n    del __data_summary_dfs\n    del __data_summary_user_code_fn\nelse:\n  print(\"This DBR version does not support data profiles.\")",
       "commandTitle": "Profil de données 1",
       "commandType": "auto",
       "commandVersion": 0,
       "commentThread": [],
       "commentsVisible": false,
       "contentSha256Hex": null,
       "customPlotOptions": {},
       "datasetPreviewNameToCmdIdMap": {},
       "diffDeletes": [],
       "diffInserts": [],
       "displayType": "table",
       "error": null,
       "errorDetails": null,
       "errorSummary": null,
       "errorTraceType": null,
       "finishTime": 1766933975506,
       "globalVars": {},
       "guid": "",
       "height": "auto",
       "hideCommandCode": false,
       "hideCommandResult": false,
       "iPythonMetadata": null,
       "inputWidgets": {},
       "isLockedInExamMode": false,
       "latestAssumeRoleInfo": null,
       "latestUser": "a user",
       "latestUserId": null,
       "listResultMetadata": [
        [
         "mimeBundle",
         null
        ]
       ],
       "metadata": {
        "byteLimit": 2048000,
        "rowLimit": 10000
       },
       "nuid": "606ce6e1-5164-479e-8fc1-37227cfbeb69",
       "origId": 0,
       "parentHierarchy": [],
       "pivotAggregation": null,
       "pivotColumns": null,
       "position": 8.5,
       "resultDbfsErrorMessage": null,
       "resultDbfsStatus": "INLINED_IN_TREE",
       "results": null,
       "showCommandTitle": false,
       "startTime": 1766933972987,
       "state": "input",
       "streamStates": {},
       "subcommandOptions": null,
       "submitTime": 1766933972955,
       "subtype": "tableResultSubCmd.dataSummary",
       "tableResultIndex": 0,
       "tableResultSettingsMap": {},
       "useConsistentColors": false,
       "version": "CommandV1",
       "width": "auto",
       "workflows": null,
       "xColumns": null,
       "yColumns": null
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, trim, count\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "client_id     = dbutils.secrets.get(scope=\"kv-olist\", key=\"secret-client-id\")\n",
    "tenant_id     = dbutils.secrets.get(scope=\"kv-olist\", key=\"secret-tenant-id\")\n",
    "client_secret = dbutils.secrets.get(scope=\"kv-olist\", key=\"secret-client-mdp\")\n",
    "\n",
    "storage_account = \"oliststorageaccountbth74\"\n",
    "container_name = \"data\"\n",
    "\n",
    "spark.conf.set(f\"fs.azure.account.auth.type.{storage_account}.dfs.core.windows.net\", \"OAuth\")\n",
    "spark.conf.set(f\"fs.azure.account.oauth.provider.type.{storage_account}.dfs.core.windows.net\", \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\")\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.id.{storage_account}.dfs.core.windows.net\", client_id)\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.secret.{storage_account}.dfs.core.windows.net\", client_secret)\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.endpoint.{storage_account}.dfs.core.windows.net\", f\"https://login.microsoftonline.com/{tenant_id}/oauth2/token\")\n",
    "\n",
    "\n",
    "df_sellers=spark.read.format(\"delta\").load(f\"abfss://{container_name}@{storage_account}.dfs.core.windows.net/silver/olist_sellers_dataset\")\n",
    "\n",
    "df_sellers=df_sellers.withColumnRenamed(\"seller_zip_code_prefix\",\"seller_zip_code\")\n",
    "\n",
    "df_sellers=df_sellers.withColumn(\"seller_id\", trim(col(\"seller_id\")))\n",
    "df_sellers_unique=df_sellers.dropDuplicates([\"seller_id\"])\n",
    "\n",
    "df_sellers_unique.write.format(\"delta\").mode(\"overwrite\").save(f\"abfss://{container_name}@{storage_account}.dfs.core.windows.net/gold/olist_dim_sellers\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "SILVER_TO_GOLD",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
